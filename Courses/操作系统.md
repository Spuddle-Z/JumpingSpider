---
tags:
  - Knowledge
  - Code
aliases:
  - Operating System
---
## 概论
> [!definition] 指令集架构 (Instruction Set Architecture, ISA)
> 其定义了软件可以使用的指令集合，也即为CPU提供给软件的接口。

## 内存管理
### 操作系统管理页表映射
操作系统在启动时，填写自己的页表，将所有的物理地址映射到虚拟地址上，这样所有物理地址就皆在操作系统的管理之内了。
> [!definition] 直接映射 (Direct Mapping)
> 虚拟地址=物理地址+固定偏移量，这样的映射方法叫做直接映射。

操作系统启动时没有能力做什么复杂的映射，只能先使用直接映射来得到虚拟地址。因此，内核空间的页表项对应的物理地址是连续的。


进程在创建时，由操作系统来填写进程页表，有两种映射方法，分别为*立即映射*和*延迟映射*。

> [!definition] 立即映射
> 操作系统按照以下四步来填写进程页表：
> 1. 分配物理页；
> 2. 将应用代码与数据从磁盘读入物理页；
> 3. 添加虚拟页到物理页的映射关系；
> 4. 若未加载完毕，则回到第一步。

立即映射的优点是简单，一次映射就能支持整个应用程序运行；缺点是浪费加载时间与物理内存，因为应用程序的代码和数据可能不会全部用到。

> [!definition] 延迟映射
> 与立即映射相对，延迟映射不会一次性将应用程序的所有代码和数据都加载到物理内存中，只有触发了缺页异常时才会继续添加映射。

进入用户态之后，由虚拟地址转换为物理地址的过程在AARCH64架构下如下图所示：
![[page_table.png|600]]

> [!definition] ASID (Address Space ID)
> 用来防止不同进程在TLB中保存页号相同的页表项时产生混淆。

### 虚拟内存管理
> [!definition] 虚拟内存空间 (Vistual Memory Area, VMA)
> VMA是Linux中记录进程已分配虚拟内存区域的结构体。每个VMA都有一个起始地址和一个结束地址，记录了该区域的权限、映射的文件、映射的偏移量等信息。

### 物理内存管理
物理内存分配器的指标：资源利用率与分配性能。
![[segment_type.png|475]]

> [!definition] 伙伴系统 (Buddy System)
> 用来避免外部碎片，其原理如下图：
> ![[buddy_system.png|525]]

> [!caution] 
> - 对于内核来说，已映射的地址不一定在使用（需要通过kmalloc才能使用）；
> - 对于应用来说，正在使用的地址不一定被映射（延迟映射）；
> - 同一个物理地址可能有多个虚拟地址（如物理地址先映射到内核空间，再映射到用户空间，此时就相当于用户与内核分别有一个虚拟地址被映射到了同一个物理地址上）。

> [!definition] 换页机制 (Swapping)
> 当物理内存不够用的时候，将内存中的某些页换出到磁盘上，从而使虚拟内存不受物理内存大小的限制。

> [!note] 总结
> - 引入虚拟内存管理之后，物理内存分配主要在以下四个场景出现：
> 	1. 用户态应用程序触发延迟映射时；
> 	2. 内核自己申请内存并使用时；
> 	3. 发生换页时；
> 	4. 内核申请用于设备的DMA内存时。
> - 导致缺页异常的三种原因：
> 	1. 访问非法的虚拟地址；
> 	2. 延迟映射，尚未分配到物理页；
> 	3. 内存页被换出到磁盘上。

> [!definition] 颠簸现象 (Thrashing)
> 颠簸现象是指系统频繁发生缺页异常，导致CPU利用率很低，而调度器会载入更多进程来提高CPU利用率，导致触发更多的缺页异常，最终使系统性能急剧下降的现象。

> [!definition] 工作集 (Working Set)
> 工作集$W(t,x)$是指在时间点$t$之前的时间段$x$内进程使用的内存页集合，且系统认为其在未来$x$的时间段内还会被继续使用。

处理函数会定时扫描内存页：
- 若访问位为1，则表示该页在此周期内被访问过，将上次使用时间更新为当前时间；
- 若访问位为0，则表示该页在此周期内未被访问过，对比上次使用时间与当前时间，若超过了$x$，则将其从工作集中移除；
- 最后将所有访问位清零。

物理内存管理的评价指标：
- *资源利用率*：尽可能避免内外部碎片；
- *分配速度*：减少内存分配与释放操作的时延；
- *分配公平性*：避免某些应用独占大量内存。

## 进程管理
### 进程
#### 基本概念
> [!definition] 进程 (Process)
> 进程是操作系统对一个正在运行的程序的抽象，可分为*静态部分*（代码与数据）和*动态部分*（程序计数器、寄存器、栈、堆等）。

> [!definition] 进程标识符 (Process ID, PID)
> PID是操作系统用来标识进程的唯一标识符。

一个CPU在同一时间只能运行一个进程，但是操作系统可以通过不断切换进程来实现多个进程同时运行的效果。此时，操作系统在切换到下一个进程前，需要记录当前进程的状态，以便下次切换回来时能够恢复到之前的状态。

> [!definition] 处理器上下文 (CPU Context)
> 处理器上下文即是进程切换前需要保存的状态，包括程序计数器、寄存器、栈指针、堆指针等。

> [!definition] 进程控制块 (Process Control Block, PCB)
> PCB是操作系统管理进程的数据结构，包含了进程的所有信息，如进程状态、进程ID、进程上下文等。

进程状态分为五种，方便操作系统管理进程：
- **新生态 (New)**：进程正在初始化，还没准备好被调度；
- **就绪态 (Ready)**：进程已经准备好，随时准备执行；
- **运行态 (Running)**：进程正在执行；
- **僵尸态 (Zombie)**：进程已经退出，但未被回收；
- **终止态 (Terminated)**：进程退出且被回收。
![[process_state.png|650]]

#### 进程相关操作
进程创建可分为四个步骤：
1. 初始化PCB
	- 初始化虚拟内存；
	- 分配物理页，作为进程的内核栈；
		![[build_process_1.png|350]]
	> [!example] 
	> - 使用`fork()`创建进程时，会将PCB复制一份，只通过`fork()`的返回值来区分父进程和子进程（父进程）；
	> - `clone()`则是比`fork()`更灵活的进程创建方法，它可以通过调整参数来指定子进程需要拷贝父进程的哪些部分。
1. 加载可执行文件
	![[build_process_2.png|650]]
1. 准备运行环境
	![[build_process_3.png|650]]
1. 初始化CPU上下文
	![[build_process_4.png|450]]

进程调度的目的是选出下一个可以执行的进程，即处于就绪态的进程。

进程切换需要进出内核，共包含五个步骤：
![[process_switch.png|300]]
1. 进程1进入内核态；
2. 保存进程1的CPU上下文；
3. 进程上下文切换；
4. 恢复进程2的CPU上下文；
5. 进程2返回用户态。

![[process_switch 2.png|650]]

> [!note] 辨析CPU上下文与进程上下文：
> - CPU上下文是用于保存切换时寄存器状态的；
> - 进程上下文则是表示目前操作系统正在以哪个进程的身份运行，通常是使用一个指向PCB的指针来表示。
> 	![[context_dif.png|300]]

### 线程
#### 基本概念
创建进程的开销较大，进程之间的隔离性过强，且无法实现多核同时处理一个进程的任务。为实现单一进程跨核执行，引入线程的概念。

> [!definition] 线程 (Thread)
> 线程只包含了进程的动态部分，这是执行所需的最小单元，静态部分则由进程来提供。因此一个进程可包含多个线程，同进程内的每个线程共享一个地址空间。

> [!caution] 
> - 与进程不同的是，一个线程执行系统调用时，可能会影响该进程上的所有线程；
> - 实际使用中，调度的对象通常是线程，之前提到的进程调度，实际可以看作是对单线程进程的调度。

> [!definition] 线程控制块 (Thread Control Block, TCB)
> TCB是操作系统管理线程的数据结构，与PCB类似，其包含了线程的信息，如所对应的进程、线程上下文等。

#### 线程相关操作
每个进程会自带一个主线程，在此基础上：
- `pthresd_create()`：创建一个新线程；
- `pthread_join()`：等待一个线程结束；
- `pthread_detach()`：将一个线程设置为分离态，使其无法被其它线程影响，并且在结束后自动回收；
- `pthread_exit()`：结束当前线程；
- `exit()`：结束当前进程（即结束此进程内的所有线程，包括分离态的线程）。

线程创建是由`clone()`函数来实现的，其本质就是创建一个与旧“进程”共享地址空间的新“进程”，并为其配置多个标记，从而使之成为一个线程。

### CPU调度
#### 单用户调度
- **对象**：CPU执行的最小单元，可能是进程或线程，此处统一以“任务”来表示；
- **时机**：执行时间用尽、等待I/O、任务睡眠或中断等；
- **决策**：下一个要执行的任务、执行该任务的CPU、执行时长。

![[CPU_scheduling.png|425]]

> [!definition] 多级反馈队列 (Multi-level Feedback Queue, MLFQ)
> 不需要先验知识（如任务长短、I/O需求是否密集等），可以通过任务运行历史来总结任务的特征。其遵循以下规则：
> 1. 优先级高的任务先执行；
> 2. 每个任务会被分配时间片，优先级相同的任务按照时间片轮流执行；
> 3. 任务被创建时，假设该任务是短任务，分配到最高优先级；
> 4. 一个任务的时间片耗尽后，其优先级会被降低一级，未耗尽的时间片会被保留；
> 5. 若一个任务的时间片耗尽，则强制降低优先级，无论其主动放弃了多少次CPU；
> 6. 在某个时间段后，将系统中所有任务的优先级升到最高。

- 第3、4条规则令短任务优先级高于长任务，保证了一些交互式任务的响应速度；
- 第5条规则防止了I/O密集型任务不会长期占用CPU；
- 第6条规则防止了过多的短任务导致的长任务饥饿。

#### 多用户调度
> [!definition] 公平共享调度 (Fair-Share Scheduling)
> 公平共享调度的核心思想是为每个用户分配一定权重的资源，而某个用户的任务只能使用该用户分配到的资源。

公平共享调度的一种实现方法是彩票调度。

> [!definition] 彩票调度 (Lottery Scheduling)
> **彩票(Ticket)**代表任务的份额，每次调度时会从所有彩票中随机抽取一个，该彩票对应的任务即可获得CPU的使用权。
> 
> 若任务A需要与任务B通信，则任务A会对任务B进行**彩票转让(Ticket Transfer)**，任务B在完成通信后会将彩票还给任务A。

> [!caution] 份额与优先级的区别
> 优先级更高的任务严格优先执行，而份额更多的任务只是获得更多的执行机会。

> [!definition] 步幅调度 (Stride Scheduling)
> 步幅调度是将权重高的任务分成更多的份数，总长度一样的情况下，先执行进度最短的任务。
> ![[stride_scheduling.png|300]]

> [!definition] 完全公平调度 (Completely Fair Scheduler, CFS)
> CFS是Linux中的公平共享调度算法，其引入了**虚拟运行时间(Virtual Runtime, VR)**的概念，其公式为
> $$VR=\frac{T}{ticket}$$
> 其中$T$为任务运行时间。

#### 多核调度
> [!definition] 负载均衡 (Load Balancing)
> 由于每个CPU都会维护一个本地运行队列，所以可能存在这些CPU负载不均衡的情况，此时操作系统会将任务从负载高的CPU上迁移到负载低的CPU上，称为负载均衡。

> [!note] 
> 操作系统提供了任务**亲和性(Affinity)**的接口，可以由此指定任务只能在某些CPU上运行。

### 进程间通信 (Inter-Process Communication, IPC)
#### 简单IPC
数据传递的两种方法：
- **共享内存**：两个进程共享同一块内存，通过读写该内存来传递数据；
- **系统调用**：调用操作系统提供的接口`send()`和`recv()`，通过内核态内存来传递数据。

通知机制的两种方法：
- **轮询**：进程不断地检查某个内存地址的值，若发生变化则说明有通知；
- **控制流**：由内核统一控制进程的运行状态。

管道与消息队列都是由内核维护的缓冲区，用于进程间通信。二者的区别在于：
- **缓存区设计**：管道的缓冲区是提前分配的固定内存空间，消息队列则为链表结构，可以动态分配；
- **消息格式**：管道只能传递无格式的字节流，消息队列则可以传递带类型的数据；
- **连接上的进程**：管道最多只能连接两个进程，消息队列则可以有多个发送者与接收者；
- **消息读取**：管道只遵循FIFO(First In First Out)原则，消息队列在FIFO的基础上，还可以基于消息类型去查询。

#### 并发与锁
> [!definition] 竞争条件 (Race Condition)
> 当两个或以上线程同时对共享的数据进行操作，其中至少有一个写操作的情况，称为竞争条件。若程序运行过程中出现了竞争条件，其结果可能会出现不确定性。

> [!definition] 临界区 (Critical Section)
> 临界区是避免竞争条件出现的一种抽象。其实现有以下三个要求：
> - 同时刻只能有一个线程进入临界区；
> - 一个线程申请进入临界区之后，必须在有限的时间内获得进入许可；
> - 没有线程在临界区中时，必须在申请进入临界区的线程中选择一个进入。
> 	![[critical_section.png|180]]

> [!definition] 互斥锁 (Mutual Exclusion Lock)
> 互斥锁是一种实现临界区的方法，其包含了两个操作：
> - `lock()`：申请进入临界区；
> - `unlock()`：退出临界区。

互斥锁的实现需要基于硬件原子指令，如`test_and_set()`。

互斥锁分为两类：
- > [!definition] 自旋锁 (Spinlock)
	> 自旋锁是一种忙等待的互斥锁，它会不断循环检查锁是否被释放，直到获取到锁为止。
- > [!definition] 排号锁 (Ticket Lock)
	> 排号锁会遵循竞争者到达的顺序传递锁，保证公平性。

> [!definition] 读写锁 (Read-Write Lock)
> 允许多个线程同时读，但只能有一个线程写（互斥锁无论读写，同时间都只能有一个线程进入临界区）。

> [!definition] 条件变量
> 条件变量利用睡眠-唤醒机制来避免无意义的等待。其提供了两个接口：
> - `cond_wait`：等待接口，阻塞当前线程，同时释放锁，被唤醒后再获取锁；
> - `cond_signal`：唤醒接口，检查等待队列，若有等待者则唤醒其中一个。

> [!definition] 信号量 (Semaphore)
> 信号量是对空闲资源的一种抽象，其包含了两个操作：
> - `wait()`：资源被占用则阻塞当前线程，申请到资源后`S++`；
> - `signal()`：`S--`，并唤醒等待队列中的一个线程。

> [!example] 
> 当`value`大于0时，代表空闲的资源；当`value`小于0时，代表等待的线程数。
> 
> 然而当其它线程刚刚释放资源时，`value`可能依然为负，但实际上已经腾出了空闲资源，此时引入`wakeup`代表可以唤醒的等待线程数量，在`value`为负时，帮助表示可用资源（`value`大于等于零时，`wakeup`不再增加）。
> 
> ![[semaphore_example.png|650]]

> [!definition] 死锁 (Deadlock)
> 死锁是同步机制中会出现的一种问题，以下四条条件同时满足即为其充要条件：
> - 同时刻只能有一个线程访问；
> - 线程在等待其他线程持有的资源；
> - 线程不会抢占已经被持有的资源；
> - 循环等待（A等B，B等A）。

解决死锁的方法有以下几种：
1. 出现死锁时处理：
	- Kill所有线程；
	- 逐个kill线程，若未解决则继续kill；
	- 全部线程回滚到之前的某一状态。
1. 设计时预防死锁：
	- 避免互斥访问，如使用代理线程，所有线程都向其发送修改请求，由其统一执行；
	- 引入`trylock`，立即返回成功或失败，不会阻塞线程，即不允许持有并等待（可能会出现活锁，但其自己可以解开）；
	- 打破循环等待，如规定所有线程只能按照某一顺序获取锁，就不会出现两线程各拿一个锁，等另外一个锁的情况了。
1. 运行时避免死锁：
	- 预演判断：在分配资源前，先检查是否会出现死锁，若会则不分配。
		> [!example] 银行家算法
		> 保证系统一直处于安全状态，即能找出至少一个执行序列，令所有线程的需求都能被满足。

> [!note] 同步原语使用场景总结
> ![[synprim_cmp.png|450]]
> ![[synprim_guideline.png|475]]

## 文件系统
### INODE文件系统
#### 基本概念
> [!definition] 文件系统 (File System)
> 文件是对可命名且持久化数据的抽象，文件系统则提供了操作文件的API。

> [!definition] Inode
> Inode是对单个文件的抽象，每个文件对应一个inode，基于inode文件系统的数据结构如下：
> ![[Pasted image 20240706232959.png|650]]
> - **Inode表**：记录了inode索引，可以看作是inode的数组；
> - **Inode分配信息**：记录了inode的空闲状态；
> - **超级块 (Super Block)**：记录了磁盘块大小等基本信息，是文件系统的元数据；

#### 基本操作
- **加载文件系统**：读取超级块，并由此找到其它信息；
- **创建文件**：根据inode分配信息找到空闲的inode，更改其分配状态，返回其索引作为文件名；
- **查找文件**：根据inode号在inode表中定位到inode；
- **删除文件**：将inode的分配状态置为空闲。

对于单级inode来说，需要大量空间来存储磁盘块号，导致inode过大，此时引入多级inode。

> [!definition] 多级inode
> 其使用索引块来存储磁盘块号（索引块存储在数据区域里面），从而减小inode的大小。
> ![[multi_inode.png|500]]

> [!definition] 目录 (Dicectory)
> 目录是用来记录字符串文件名到inode号的映射关系的，其本质上也是一种有inode有文件。其所占大小与文件名数量和长度有关，与文件大小无关。

> [!example] 
> 以查找文件`/os-book/fs.tex`为例：
> ![[file_search_1.png|650]]
> ![[file_search_2.png|650]]
> ![[file_search_3.png|650]]

> [!definition] 硬链接 (Hard Link)
> 硬链接可以将一个文件名与一个inode号关联起来，从而实现通过多个文件名来访问同一个文件，也即可以将一个文件系统原来的树结构变为有向图结构。其有如下特点：

- 除`.`与`..`外，文件系统结构中不能出现环；
- 无法为目录创建硬链接（因为可能创造环）；
- 无法创建指向另一个磁盘的硬链接（因为不同磁盘中inode号的命名空间是不同的）。

> [!definition] 软链接 (Soft Link)
> 软链接则是创建一个指向文件名字符串的链接，然后通过这个字符串链接到文件。软链接可以指向另一个磁盘。

> [!definition] 元数据 (Metadata)
> 元数据是指描述数据的数据，如inode、block位图等。

磁盘中的文件元数据一般包括拥有者、权限、时间戳等信息；而内存中的文件，即被打开的文件的元数据则包括了`file_table`与`fd_table`。其中整个系统维护了一个`file_table`，它记录了所有打开的文件的信息，包括**文件游标(File Cursor)**，即当前读写到了文件的哪个位置；一个进程则维护一个`fd_table`，它记录了该进程中每个**文件描述符(File Descriptor)**对应文件在`file_table`中的索引。

> [!note] 
> 父进程会将文件描述符传递给子进程，因此父子进程可以共享文件游标；而两个不同进程则不会共享文件游标。

`fsync`操作是将内存中的文件元数据同步到磁盘中。修改磁盘数据时，操作系统会寻找机会将修改的内容批量写入，以此提高性能。

> [!example] 
> 一次`open()`需要多少次磁盘读写？一次`read()`需要多少次磁盘读写？
> ![[open_read.png|600]]

#### 文件系统的崩溃一致性
文件系统中保存的信息需要保持一致，如inode中记录的文件大小与实际文件大小、inode分配表中记录的空闲状态与实际的空闲状态等，崩溃（如突然断电）可能打破这种一致性。

> [!example] 
> 如一个`append()`操作包括三个磁盘写操作：
> 1. 写入新数据；
> 2. 更新inode；
> 3. 更新block位图。
> 
> 3个步骤，共有8种可能出现的情况，刨去全写与相当于没写的无伤大雅的情况，可能出现两种错误：
> - 只做了1、2：数据错误；
> - 做了1，但没做2：空间浪费。

解决以上问题的方法：
- **同步元数据写入 + `sync`**：每次写入元数据时，运行`sync`保证更新后的元数据入盘。
	> [!note] 
	> 若非正常重启，则运行`fsck`检查磁盘，具体步骤如下：
	> 1. 检查superblock，保证文件系统大小大于已分配的磁盘块总和；
	> 2. 检查空闲block，扫描所有inode包含的磁盘块，并与bitmap比较；
	> 3. 检查inode的状态，如是否出现类型错误的问题；
	> 4. 扫描整个文件树，核对文件链接的数量，若出现某个inode不在任何目录下，则放到`/lost+found`目录下；
	> 5. 检查是否有两个inode指向同一个磁盘块；
	> 6. 检查超出空间的磁盘ID；
	> 7. 检查目录保证保证`.`和`..`是位于头部的目录项、保证目录的链接数只能是1个、保证目录中不会有相同的文件名。

- > [!definition] 日志 (Journaling)
	> 1. 修改之前，先将修改记录到日志中；
	> 2. 记录完毕后，提交日志；
	> 3. 确定日志落盘后，再修改数据和元数据；
	> 4. 修改完成后，删除日志。

### I/O协议
设备最基本的抽象如下：
![[struct.png|550]]

传统的I/O流程是OS给设备发送指令，并不断轮询，等待设备执行，直到设备响应完请求。这种流程中，轮询会消耗太多CPU时间。

以上问题可以用**中断**解决。OS向设备发送一个请求后，便令I/O进程休眠，当设备完成请求后，触发硬件中断，CPU则跳转到**中断处理程序(Interrupt service routine, ISR)**。

对于慢速的设备（如键盘），中断是十分有效的I/O方式；但对于快速的设备（如网卡），OS则需大量处理中断，反而降低了效率。

此问题则可以用**中断+轮询**的方式解决，即网络中断发生后，使用轮询处理后续数据包，但一旦轮询时间超过限制，则回到中断模式；或是用**中断合并(Interrupt Coalescing)**的方式，即在设备发送中断之前等待一小段时间，将此段时间内的中断合并为一个中断处理。

#### 设备交互方法
> [!definition] PIO (Port Input/Output)
> PIO是通过CPU的I/O指令来与设备交互的方式。OS必须以内核态使用I/O指令。

> [!definition] MMIO (Memory-Mapped I/O)
> MMIO是将设备的寄存器映射成普通的内存，通过读写内存来实现与设备的交互。这样在用户态也可以与设备交互。

> [!example] 
> MMIO地址需使用`volatile`修饰，防止编译器优化。如以下代码：
> ```c
> void main (void) {
> 	void         *pdev = (void *) 0x40400000;
> 	size_t        size = (1024*1024);
> 	int          *base;
> 	volatile int *pcid, cid;
> 	
> 	base = mmap(pdev, size, PROT_READ|PROT_WRITE, MAP_ANONYMOUS|MAP_PRIVATE, -1, 0);
> 	if (base == MAP_FAILED) errx(1, "mmap failure");
> 	
> 	pcid = (int *) (((void *) base) + 0xf0704);
> 	cid = *pcid;
> 	printf("cid = %d\n", cid);
> 	cid = *pcid;
> 	printf("cid = %d\n", cid);
> 
> 	munmap(base, size);
> }
> ```

若不加`volatile`，编译器会第二个内存加载操作优化掉。

磁盘的读指令一般都会读取一大块数据，若读取过程全部经过CPU，效率会非常低，因此引入直接内存访问。

> [!definition] 直接内存访问 (Direct Memory Access, DMA)
> 即磁盘控制器直接读取物理内存到磁盘的内存缓冲区，不需要CPU的参与。

#### GPU
> [!definition] GPU上下文 (GPU Context)
> GPU上下文是对GPU任务的抽象，类似于CPU的进程。

> [!definition] GPU通道 (GPU Channel)
> GPU通道是GPU与CPU通信的唯一通道，其拥有自己的页表与控制域，向其发送指令可将数据和计算任务加载至一个GPU上下文，驱动通过channel descriptor来管理channel。

![[GPU.png|650]]

上图为GPU的工作流程：
- GPU Runtime（如CUDA）先将API调用转化为GPU指令；
- GPU驱动会申请一块内存作为**命令缓冲区(Command Buffer)**，CPU则通过此区域发送指令管理GPU；
- GPU先在自己的内存中创建channel，以便将指令与数据加载至GPU Context；
- 通过命令缓冲区与DMA buffer将指令与数据加载至GPU Context；
- 最后通过command buffer发送执行的命令。
