---
tags:
  - Knowledge
aliases:
  - Probability Theory
---

## 随机变量及其分布
### 基本概念
> [!definition] 期望 (Expectation)
> 度量一个随机变量取值的集中位置或平均水平的最基本的数字特征。

期望的运算性质：
1. $E(cX)=cE(X)$
2. $E(X\pm Y)=E(X)\pm E(Y)$
3. 若$X,Y$相互独立，则有$E(XY)=E(X)E(Y)$

> [!definition] 方差 (Variance)
> 表示随机变量取值的分散性的一个数字特征，一般用$\sigma^2$或$D(X)$表示，可以由期望按下式算得
> $$D(X)=E[(X-E(X))^2]=E(X^2)-E(X)^2$$

方差的运算性质：
1. $D(c)=0$
2. $D(cX)=c^2D(X)$
3. $D(X+c)=D(X)$
4. 若$X,Y$相互独立，则有$D(X\pm Y)=D(X)+D(Y)$

> [!definition] 协方差 (Covariance)
> 用来衡量两个随机变量的变化趋势是否一致。对于两个随机变量$X,Y$，其协方差为$$\sigma(X,Y)=E\left[(X-E(X))\cdot(Y-E(Y))\right]=E(XY)-E(X)E(Y)$$

从数值上来说，协方差越大，说明两个变量的同向趋势越大；协方差越小，说明两个变量的反向趋势越大；协方差越趋近于零，两个变量越不相关。

> [!definition] 协方差矩阵
> 对于$d$个随机变量，我们可以求出一个协方差矩阵：
> $$
> \Sigma=
> \begin{bmatrix}
> \sigma(X_1,X_1) & \cdots & \sigma(X_1,X_d) \\
> \vdots & \ddots & \vdots \\
> \sigma(X_d,X_1) & \cdots & \sigma(X_d,X_d)
> \end{bmatrix}
> $$
> ^yvq7oj
### 运算规律
若$a,b$为两个*相互独立*的随机变量，则有
$$
\left\{\begin{aligned}
a\sim N(\mu_1,\sigma_1^2)\\
b\sim N(\mu_2,\sigma_2^2)
\end{aligned}\right.
\implies a+b\sim N(\mu_1+\mu_2,\sigma_1^2+\sigma_2^2)
$$
对于两个向量$\alpha,\beta$，则有
$$
\left\{\begin{aligned}
\alpha\sim N(\mu_{\alpha},\sigma_{\alpha}^2)\\
\beta\sim N(\mu_{\beta},\sigma_{\beta}^2)
\end{aligned}\right.
\implies
\begin{bmatrix}
\alpha \\ \beta
\end{bmatrix}
\sim N\left(
\begin{bmatrix}
\mu_{\alpha}\\\mu_{\beta}
\end{bmatrix},
\begin{bmatrix}
\Sigma_{\alpha\alpha}&\Sigma_{\alpha\beta}\\
\Sigma_{\beta\alpha}&\Sigma_{\beta\beta}
\end{bmatrix}
\right)
$$
且有
$$P(\beta|\alpha)\sim N(\mu_{\beta}+\Sigma_{\beta\alpha}\Sigma_{\alpha\alpha}^{-1}(\alpha-\mu_{\alpha}),\Sigma_{\beta\beta}-\Sigma_{\beta\alpha}\Sigma_{\alpha\alpha}^{-1}\Sigma_{\alpha\beta})$$
## 参数估计
> [!definition] 似然函数 (Likelihood Function)
> 对于函数$P(x|\theta)$，其中$x$表示实际数据，$\theta$表示模型参数，则若$x$固定，$P(x|\theta)$随$\theta$变化，那么这个函数叫做似然函数。

> [!note] 似然函数与概率函数
> 若$\theta$固定，$P(x|\theta)$随着$x$变化，则此函数是一个固定模型的概率函数。

> [!definition] 最大似然估计 (Maximum Likelihood Estimation, MLE)
> 当我们有一组数据$x_1,x_2,\cdots,x_{n}$时，我们需要求出那个最可能得出这组数据的模型参数$\theta^*$，也即求$$\mathop{\arg\max}\limits_{\theta}\prod_{i=1}^{n}P(x_i|\theta)\equiv\mathop{\arg\max}\limits_{\theta}\sum_{i=1}^{n}\log P(x_i|\theta)$$ ^tyfz0r
## Logit
> [!definition] Odds
> 是用来表示概率大小的量，不过概率的取值范围为$[0,1]$，而odds的取值范围为$[0,+\infty)$，其公式为
> $$Odds(P)=\frac{P}{1-P}$$

> [!definition] Logit函数
> 在odds的基础上取对数，即可得到Logit
> $$Logit(P)=\log Odds(P)=\log\frac{P}{1-P}$$
> 其图像如下：
> ![[Pasted image 20240317154521.png|400]]

> [!definition] Sigmoid函数
> 是Logit的反函数
> $$\sigma(x)=\frac{1}{1+e^{-x}}$$
> ![[Pasted image 20240317155319.png|400]]
## 数据的基本统计描述
### 中心趋势
对于平均数(Mean)、中位数(Median)与众数(Mode)，在数据分布为*单峰*时有此经验公式：
$$Mean-Mode\simeq 3\times(Mean-Median)$$
如图所示：
![[Pasted image 20240304102748.png|650]]
### 离散程度
> [!definition] 标准差 (Standard Deviation)
> 是方差的平方根，即$\sigma$。

无论数据如何分布，至少有$1-\frac{1}{k^2}$的点在$Mean\pm k\sigma$之内
> [!definition] 四分位数 (Quartile)
> - $Q_1$：下四分位数，25%
> - $Q_3$：上四分位数，75%
> - $IQR$：四分位距，$IQR=Q_3-Q_1$
### 数据统计常用图
> [!definition] 箱形图 (Boxplot)
> ![[Pasted image 20240227165111.png|450]]
> - **下限(Min)**：$Q_1 - 1.5*IQR$
> - **上限(Max)**：$Q_3 + 1.5*IQR$
> - **异常值(Outlier)**：落在上下限之外的点

> [!definition] 分位图 (Quantile-Quantile Plot, Q-Q Plot)
> 使用两组数据中的同一位置的分位数作为一个点的横纵坐标。

> [!example] 
> ![[Pasted image 20240304110136.png|450]]
> 如图可知，Branch 1的价格更低。
## 大数定律和中心极限定理
> [!definition] 马尔可夫不等式 (Markov's Inequality)
> 对于非负随机变量$X$，$\forall c>0$：
> $$P(X\geq c)\leq\frac{\mathbb{E}[X]}{c}$$

> [!proof] 
> $$
> \begin{aligned}
> \mathbb{E}[X]&=\int_0^cxf(x)\ dx+\int_c^\infty xf(x)\ dx \\
> &\geq\int_c^\infty xf(x)\ dx \\
> &\geq c\int_c^\infty f(x)\ dx \\
> &=c\cdot P(X\geq c)
> \end{aligned}
> $$

> [!definition] 切比雪夫不等式 (Chebyshev's Inequality)
> 对于$\forall c>0$：
> $$P\left(|X-\mu|\geq c\right)\leq\frac{\sigma^2}{c^2}$$

> [!proof] 
> $$
> \begin{aligned}
> P\left(|X-\mu|\geq c\right)&=P\left((X-\mu)^2\geq c^2\right)\\
> &\leq\frac{\mathbb{E}\left[(X-\mu)^2\right]}{c^2}(\text{Markov's
> inequality})\\
> &=\frac{\sigma^2+\mathbb{E}^2\left[(X-\mu)\right]}{c^2}\\
> &\leq\frac{\sigma^2}{c^2}
> \end{aligned}
> $$

> [!definition] 切尔诺夫界 (Chernoff Bound)
> 设$X_1,...,X_t$是一串在$[0,1]$范围内独立同分布的随机变量，其期望值为$\mu$，则对于这$t$个变量的均值$X=\frac{1}{t}\sum_iX_i$，当$0<\delta<1$时，有
> $$P(|X-\mu|\geq\delta\mu)\leq2\exp\left(-\frac{\delta^2\mu t}{3}\right)$$
