---
tags:
  - Knowledge
---
# 背景
对于图片识别来说，如果将一张图片按每个像素点拉成一个向量，把这个向量作为神经网络的输入，则整个神经网络需要极其巨大的参数量，要去训练这个模型几乎是不可能的，并且图片识别的两个特性说明这个输入向量的一些特征是不重要的。这两个特性是**平移不变性**与**局部性**。

- 平移不变性：目标位置的改变并不影响其识别；
- 局部性：识别目标不需要看到图片的整体。

问题中这两个特性的存在，允许我们可以适当削减模型的复杂度，减少训练代价并获得同样的效果。

# 基础CNN
此时引入卷积层，这是一个特殊的全连接层，利用卷积核的平移采集局部特征。这样就使得卷积核内的参数可以被重复使用，大大减少了参数数量。

得到卷积核的过程同样利用机器学习的思路，给定输入X与输出Y，通过梯度下降最小化损失函数。

实际图片中，我们想要的特征可能会发生小幅平移或旋转，如果卷积层对位置太敏感，则会降低模型效果。

此时引入**池化**(Pooling)操作，保留窗口内的最大值（最大池化）或平均值（平均池化），从而突出目标特征，降低卷积层对位置的敏感性。

# AlexNet、VGG与NiN
AlexNet优化了一些细节：
- 将激活函数从Sigmoid变成ReLU；
- 将平均池化改为最大池化。

VGG则引入了**VGG块**（VGG Block）的概念。将数个3×3卷积层与一个2×2的池化层组合成一个VGG块，通过堆叠这样的VGG块来得到更大更深也更规整的CNN。

NiN则通过用1×1的卷积层替代卷积层后的第一个全连接层。这个操作相当于将每个通道看作一个元素，做了一个通道之间的全连接层，而非把通道内向量中的每一个数看作是一个元素，这样极大地减少了这一层的参数量，同时也有效地削减了维度。

# 从GoogLeNet到ResNet
二者的设计中用到了相似的思想，即将数种结构平行地写入网络中，由网络自主选择路径。

GoogLeNet引入了inception块，其结构如图：
![[inception.png|475]]

inception块中每一条平行路径都是一个通道，输出则综合了4个通道的结果。与3×3的单层卷积层相比，inception块反而有更少的参数量与复杂度，却融合了更多的结构。

ResNet则是加入了一条与其它结构平行的快速通道，如果这些结构并未起到正向作用，那么输入将会由快速通道直接跳过这些结构。
![[ResNet.png|275]]
ResNet使卷积神经网络的深度能够达到上千层。

# 全连接卷积神经网络 Fully Convolutional Network (FCN)
**转置卷积**操作与卷积相反，可以增大输入的高宽。

**全连接卷积神经网络**将CNN顶部的线性层改为了转置卷积层，最终得到与原图大小相等的输出，且实现对原图中每个像素的分类。
![[FCN.png|129]]
# SegNet
相较于FCN，SegNet的特点是十分的对称，其结构如下图所示：
![[segNet.jpg]]

此外，segNet还引入了**池化索引**（Pooling Index），即在池化层中记录下最大值的位置，然后在转置卷积层中将最大值填入相应的位置，其余位置填0，如下图所示：
![[segNet_unpool.png]]

SegNet的训练是逐层进行的，即首先训练外层，然后固定外层，添加内层进行训练。
![[segNet_train.png]]