## 欠拟合与过拟合
为防止模型过拟合，我们需要通过**正则化(Regularization)**减小高次项系数，以消减高次项对拟合函数的影响。
    $$J(\theta)=\frac{1}{m}\left[\sum^m_{i=1}Cost(h_\theta(x),y)+\lambda\sum^m_{i=1}\theta_i^2\right]$$

选择合适的正则化参数$\lambda$，可控制$\theta_1,...,\theta_n$的值。$\lambda$过小，模型过拟合；反之，模型欠拟合。

\subsubsection{评价假设模型}

\begin{formal}

    将已有数据集随机分为两部分，训练集（training set）和测试集（test set），一般设定其比例为7:3。首先依据训练集训练出假设函数，而后将测试集代入所得函数，计算出误差。

\end{formal}

对于线性回归，其误差可用平方误差函数算得：

$$J_{test}(\theta)=\frac{1}{2m_{test}}\sum^{m_{test}}_{i=1}\left(h_\theta(x)-y\right)^2$$

对于logistic回归，其误差可直接用预测正确样本数的占比表示：

$$J_{test}(\theta)=\frac{m_{right}}{m_{test}}$$

\subsubsection{模型选择}

\begin{formal}

    与测试集不同，\textbf{交叉验证集}（cross validation set）是用来评估模型优劣的数据集。将训练集随机对半分出一个交叉验证集，先用训练集训练不同超参数下的模型，再用交叉验证集评价这些模型的优劣。

\end{formal}

\begin{example}

    以不同多项式次数（degree）的模型举例，首先依据训练集训练出不同多项式次数下的假设函数，而后将交叉验证集代入所得函数，计算出误差，即

    $$

    \left\{\begin{aligned}

        h_\theta(x)&=\theta_0+\theta_1x&,d=1 \\

        h_\theta(x)&=\theta_0+\theta_1x+\theta_2x^2&,d=2 \\

        \vdots

    \end{aligned}\right.

    \Longrightarrow

    \left\{\begin{aligned}

        J_{cv}&(\theta^{(1)}) \\

        J_{cv}&(\theta^{(2)}) \\

        \vdots

    \end{aligned}\right.

    $$

    比较各$J_{cv}(\theta^{(d)})$，得出使其最小化的d值，从而确定模型的多项式次数。\par

    若引入正则项，则式子变为：

    $$

    h_\theta(x)=\sum_{i=0}^m\theta_ix^i+\frac{\lambda}{m}\sum^m_{i=1}\theta_i^2

    \left\{\begin{aligned}

        \lambda&=0 \\

        \lambda&=0.01 \\

        \lambda&=0.02 \\

        &\vdots \\

        \lambda&=10

    \end{aligned}\right.

    \Longrightarrow

    \left\{\begin{aligned}

        J_{cv}&(\theta^{(1)}) \\

        J_{cv}&(\theta^{(2)}) \\

        J_{cv}&(\theta^{(3)}) \\

        \vdots \\

        J_{cv}&(\theta^{(12)})

    \end{aligned}\right.

    $$

\end{example}

\begin{warning}

    注意事项：\\

    1. 训练集与交叉验证集不可有重合；\\

    2. 测试集只能用一次，不可以用来调整超参数。

\end{warning}

\begin{formal}

    当没有足够的数据时，可以使用\textbf{$k$-则交叉验证}。将数据去掉测试集后，随机分为$k$块（$k$常取5或10），使用其中第$i$块作为交叉验证集，其余作为训练集，在同一个模型上跑$k$次，取这$k$个交叉验证集误差的平均来评价模型。

\end{formal}

\subsubsection{分辨高偏差问题与高方差问题}

若模型效果不理想，则可能是由于两种问题：一是偏差较大（high bias），也就是模型欠拟合（underfit）；二是方差较大（high variance），即模型过拟合（overfit）。

\begin{formal}

    \begin{center}

        \includegraphics[width=0.5\textwidth]{figure/bias&variance.png}

    \end{center}

    如图所示，发生欠拟合与过拟合时，$J_{cv}(\theta)$均较大，但欠拟合时$J_{train}(\theta)\approx J_{cv}(\theta)$，而过拟合时$J_{train}(\theta)\ll J_{cv}(\theta)$。\par

    若引入正则项，则横轴正向变为$\lambda$下降方向。

\end{formal}

\subsubsection{学习曲线 Learning Curve}

\begin{formal}

    学习曲线的横轴为训练集样本个数。因此，随着样本个数上升，训练集误差将增大，交叉验证集误差则减小。\par

    对于高偏差模型，两条曲线最终趋近于一较高误差，此时即使样本增大，模型效率也很难再提高；对于高方差模型，两条曲线接近速度较慢，但当样本增多时，交叉验证集误差可持续减小。

    \begin{center}

        \includegraphics[width=0.4\textwidth]{figure/biasLC.png}

        \includegraphics[width=0.37\textwidth]{figure/varianceLC.png}

    \end{center}

\end{formal}

\subsubsection{修正模型方法总结}

\begin{formal}

    对于高偏差模型：\\

    a. 增加特征（可人工找出错误样本特点，有针对性地增加特征）；\\

    b. 增加多项式次数；\\

    c. 降低$\lambda$值；\par

    对于高方差模型：\\

    a. 削减特征；\\

    b. 增加训练样本；\\

    c. 升高$\lambda$值。

\end{formal}

\subsubsection{不对称性分类的误差评估}

\begin{warning}

    对于一个实际问题，一般先建立一个非常简单的模型，而后绘制出学习曲线，确定一个可以反映模型效果的数值评价指标（如交叉验证错误率），再据此改进模型。

\end{warning}

但对于一些特殊的例子，一般的评价方法则不一定适用。

\begin{example}

    对于一个癌症分类模型，人群中只有约0.5\%患有癌症，因此，当模型误差为1\%时，其表现出的误差会比一个将所有人都判断为不患癌的模型误差更大，但不能说明后者优于前者。

\end{example}

这种样本中某一类数据非常少的情况称为偏斜类问题（skewed classes）。此时引入查准率（precision）与召回率（recall）来评估模型。

\subsubsection{二分类模型的综合评价指标}

\begin{formal}

    \begin{center}

        \includegraphics[width=0.5\textwidth]{figure/precisionRecall.png}

    \end{center}

    结合上图，查准率$P$与召回率$R$分别为：

    $$

    \left\{\begin{aligned}

        P&=\frac{TP}{TP+FP} \\

        R&=\frac{TP}{TP+FN}

    \end{aligned}\right.

    $$

    二者均是数值越高，模型越好。提升0和1之间的临界值，可提高查准率；反之，可提高召回率。

\end{formal}

\begin{formal}

    引入$F_1$值（$F_1$ score）来综合评估查准率与召回率：

    $$F_1=\frac{2PR}{P+R}$$

    同样可以用交叉验证集来自动选择查准率与召回率。

\end{formal}

\subsubsection{多分类模型的综合评价指标}

对于多分类模型，根据不同需要，可有多种评价模型。

\begin{formal}

    Macro度量是基于类别的加权平均，每个类别权重相同。其查准率、召回率与$F_1$值有如下定义：

    $$

    \left\{\begin{aligned}

        P_{macro}&=\frac{1}{n}\sum_{i=1}^n\frac{TP_i}{TP_i+FP_i} \\

        R_{macro}&=\frac{1}{n}\sum_{i=1}^n\frac{TP_i}{TP_i+FN_i} \\

        F_{1macro}&=\frac{2P_{macro}R_{macro}}{P_{macro}+R_{macro}}=\frac{1}{n}\sum_{i=1}^nF_{1i}

    \end{aligned}\right.

    $$

\end{formal}

\begin{formal}

    Micro度量是基于样本数的加权平均，每个样本的权重相同。其查准率、召回率与$F_1$值有如下定义：

    $$

    \left\{\begin{aligned}

        \overline{TP}&=\frac{1}{n}\sum_{i=1}^nTP_i \\

        \overline{FP}&=\frac{1}{n}\sum_{i=1}^nFP_i \\

        \overline{FN}&=\frac{1}{n}\sum_{i=1}^nFN_i \\

        P_{micro}&=\frac{\overline{TP}}{\overline{TP}+\overline{FP}} \\

        R_{micro}&=\frac{\overline{TP}}{\overline{TP}+\overline{FN}} \\

        F_{1micro}&=\frac{2P_{micro}R_{micro}}{P_{micro}+R_{micro}}

    \end{aligned}\right.

    $$

    此处由于$\overline{FP}=\overline{FN}$，可推得

    $$P_{micro}=R_{micro}=F_{1micro}$$

\end{formal}